{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amedyukhina/biomassters/blob/main/biomassters_all_times_unet_3D_all_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx6C6_iftB_Q"
      },
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "\n",
        "pandas==1.3.5\n",
        "scikit-learn==1.0.2\n",
        "tqdm==4.64.0\n",
        "numpy==1.21.6\n",
        "torch\n",
        "torchvision\n",
        "scikit-image\n",
        "matplotlib\n",
        "pytorch_lightning\n",
        "urllib3==1.25.4\n",
        "monai==0.9.1\n",
        "wandb\n",
        "boto3==1.26.16\n",
        "rasterio==1.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MJpKepBtPk4"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Im8wt6KtRot"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "\n",
        "from cachetools import cached, TTLCache, MRUCache\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Compose, Normalize\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torchvision.io import read_image\n",
        "from torchvision import transforms\n",
        "from pytorch_lightning import LightningModule, Trainer\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
        "import pytorch_lightning as pl\n",
        "import warnings\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import shutil\n",
        "from scipy import ndimage\n",
        "from monai.networks.layers import Norm\n",
        "from monai.networks.nets import UNet, DynUNet\n",
        "from monai.inferers import sliding_window_inference\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb9UyntbtSEu"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj03wxuVAzkO"
      },
      "outputs": [],
      "source": [
        "with open('gdrive/MyDrive/Personal/wandb_apikey') as f:\n",
        "    key = f.read()\n",
        "\n",
        "os.environ['WANDB_API_KEY'] = key.rstrip('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dEE28TBs1ps"
      },
      "source": [
        "### Prepare list of chip IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH_DBwXlaioL"
      },
      "outputs": [],
      "source": [
        "feature_path = 'gdrive/MyDrive/biomassters/info/features_metadata.csv'\n",
        "data_path = 'gdrive/MyDrive/biomassters/data/'\n",
        "train_img_dir ='train_features'\n",
        "test_img_dir = 'test_features'\n",
        "label_dir = 'train_agbm'\n",
        "model_checkpoint_path = 'gdrive/MyDrive/biomassters/models/'\n",
        "MODE = 'S2'\n",
        "nval = 100\n",
        "PATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbzAKgvbzPC4"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(feature_path)\n",
        "df_pred = df[df['split'] == 'test'].reset_index(drop=True)\n",
        "pred_ids = np.unique(df_pred['chip_id'])\n",
        "df = df[df['split'] == 'train'].reset_index(drop=True)\n",
        "all_ids = np.unique(df['chip_id'])\n",
        "\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(all_ids)\n",
        "train_ids = all_ids[:-nval]\n",
        "val_ids = all_ids[-nval:]\n",
        "len(all_ids), len(train_ids), len(val_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UjNA0fHs_Yq"
      },
      "source": [
        "### Set up data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP_tzGsX8Ayj"
      },
      "outputs": [],
      "source": [
        "cache = MRUCache(maxsize=1000) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5ro-QSNDvJN"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.config import Config\n",
        "import rasterio\n",
        "\n",
        "# Our rasters contain no geolocation info, so silence this warning from rasterio\n",
        "warnings.filterwarnings(\"ignore\", category=rasterio.errors.NotGeoreferencedWarning)\n",
        "\n",
        "BUCKET_NAME = 'drivendata-competition-biomassters-public-us'\n",
        "os.environ[\"AWS_NO_SIGN_REQUEST\"] = 'YES'\n",
        "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "\n",
        "# @cached(cache)\n",
        "def get_image_from_aws(fn):\n",
        "  try:\n",
        "    obj = s3.get_object(Bucket=BUCKET_NAME, Key=fn)\n",
        "    with rasterio.open(obj['Body']) as src:\n",
        "      img = src.read()\n",
        "  except:\n",
        "    img = np.zeros((len(MEANS), 256, 256))\n",
        "  return img\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL07qrNR4WSk"
      },
      "outputs": [],
      "source": [
        "# @cached(cache)\n",
        "def get_image(fn):\n",
        "    if os.path.exists(fn):\n",
        "        img = io.imread(fn)\n",
        "        if img.shape[-1] < 20:\n",
        "            img = np.moveaxis(img, -1, 0)\n",
        "    else:\n",
        "        img = np.zeros((len(MEANS), 256, 256))\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oXIIMKMCRWs"
      },
      "outputs": [],
      "source": [
        "MEANS, STDS = np.load(data_path + rf'{MODE.lower()}_mean_std.npy')\n",
        "MEANS = MEANS.reshape(-1,1,1)\n",
        "STDS = STDS.reshape(-1,1,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV0wP2UTwckg"
      },
      "source": [
        "### Define a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N_LputV837B"
      },
      "outputs": [],
      "source": [
        "class SentinelDataset2(Dataset):\n",
        "    def __init__(self, chip_ids, img_dir, label_dir=None, \n",
        "                 transform=None):\n",
        "        self.chip_ids = chip_ids\n",
        "        self.img_dir = img_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.chip_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = []\n",
        "        for month in range(12):\n",
        "            img = get_image_from_aws(os.path.join(self.img_dir, \n",
        "                                                  rf\"{self.chip_ids[idx]}_{MODE}_{month:02d}.tif\"))\n",
        "            img = torch.tensor(img.astype(np.float32))\n",
        "            image.append(img)\n",
        "        image = torch.stack(image)\n",
        "        t, c, h, w = image.shape\n",
        "        \n",
        "        if self.label_dir is not None:\n",
        "            label = get_image_from_aws(os.path.join(self.label_dir, \n",
        "                                                    rf\"{self.chip_ids[idx]}_agbm.tif\"))\n",
        "            label_filt = ndimage.median_filter(label[0], 3)\n",
        "            label_filt = torch.tensor(label_filt.astype(np.float32)).unsqueeze(0)\n",
        "            label = torch.tensor(label.astype(np.float32))\n",
        "        else:\n",
        "            label = label_filt = None\n",
        "\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(torch.concat([image.reshape(t*c, h, w), \n",
        "                                                 label, label_filt]))\n",
        "            label = image[-2:-1]\n",
        "            label_filt = image[-1:]\n",
        "            # image = image[:-2].reshape(t, c, PATCH_SIZE, PATCH_SIZE)\n",
        "            image = image[:-2].reshape(t, c, h, w)\n",
        "\n",
        "        image = torch.stack([(img - torch.tensor(MEANS))/torch.tensor(STDS) \n",
        "                for img in image])\n",
        "            \n",
        "        return image, label, label_filt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJU6P5pKtlco"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(degrees=180),\n",
        "        # transforms.RandomCrop(PATCH_SIZE, pad_if_needed=True),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1hG_s0QtOpq"
      },
      "outputs": [],
      "source": [
        "train_ds = SentinelDataset2(train_ids, train_img_dir, label_dir, \n",
        "                            transform=train_transforms\n",
        "                            )\n",
        "val_ds = SentinelDataset2(val_ids, train_img_dir, label_dir)\n",
        "train_dataloader = DataLoader(train_ds, batch_size=4, \n",
        "                              shuffle=True, num_workers = 2)\n",
        "valid_dataloader = DataLoader(val_ds, batch_size=4, \n",
        "                              shuffle=False, num_workers = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Xi1fWEJ0L0j"
      },
      "outputs": [],
      "source": [
        "torch.random.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YSYs63atOsc"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "imgs, labels, labels_filt = next(iter(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eTRmZKJtOvx"
      },
      "outputs": [],
      "source": [
        "imgs.shape, labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ULgNtJq2er_"
      },
      "outputs": [],
      "source": [
        "cols = 5\n",
        "rows = 2\n",
        "s = 3\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(s*cols, s*rows))\n",
        "for img, ax in zip(imgs[0][10], axes.ravel()):\n",
        "    ax.imshow(img.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wswKZm5Z9Gyx"
      },
      "outputs": [],
      "source": [
        "# Show ground truth\n",
        "plt.imshow(labels_filt[0][0].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mTHkbGe23xU"
      },
      "source": [
        "### Define the model and the training pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU78ehFP2N4l"
      },
      "outputs": [],
      "source": [
        "class Sentinel2Model(pl.LightningModule):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        img, _, label = batch\n",
        "        # img, label, _  = batch\n",
        "        predicted = self.model(img)\n",
        "        loss = F.mse_loss(predicted, label)\n",
        "        self.log(\"train/loss\", loss)\n",
        "        self.log(\"train/rmse\", torch.sqrt(loss))\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        img, label, label_filt = batch\n",
        "        predicted = self.model(img)\n",
        "        loss = F.mse_loss(predicted, label_filt)\n",
        "        self.log(\"valid_loss\", loss)\n",
        "        self.log(\"valid_rmse\", torch.sqrt(loss))\n",
        "        self.log(\"valid_rmse_nonfilt\", torch.sqrt(F.mse_loss(predicted, label)))\n",
        "        return loss\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.02)\n",
        "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "        return [optimizer], [scheduler]\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdT5SQKl2N8K"
      },
      "outputs": [],
      "source": [
        "kernels = [[1, 5, 5], [3, 3, 3], [1, 3, 3], [3, 3, 3], [1, 3, 3]]\n",
        "strides = [[1, 1, 1], [2, 2, 2], [1, 2, 2], [2, 2, 2], [1, 2, 2]]\n",
        "\n",
        "class Unet3D(nn.Module):\n",
        "    def __init__(self, kernels, strides):\n",
        "        super(Unet3D, self).__init__()\n",
        "        self.unet = DynUNet(\n",
        "            spatial_dims=3,\n",
        "            in_channels=len(MEANS),\n",
        "            out_channels=1,\n",
        "            kernel_size=kernels,\n",
        "            strides=strides,\n",
        "            upsample_kernel_size=strides[1:],\n",
        "            norm_name=\"batch\",\n",
        "            deep_supervision=False,\n",
        "            deep_supr_num=3,\n",
        "        )\n",
        "        self.conv = nn.Conv3d(12, 1, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.unet(img.transpose(1,2))\n",
        "        return self.conv(out.transpose(1,2)).squeeze(1)\n",
        "\n",
        "\n",
        "base_model = Unet3D(kernels, strides)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ4hMMaz9G1_"
      },
      "outputs": [],
      "source": [
        "s2_model = Sentinel2Model(base_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKgddBI9BX6u"
      },
      "outputs": [],
      "source": [
        "wandb_logger = WandbLogger(project='BioMassters_all_timepoints')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU0Y69VdEwUc"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "     monitor='valid_rmse',\n",
        "     dirpath=os.path.join(model_checkpoint_path, wandb.run.name),\n",
        "     filename='{epoch:02d}-{valid_rmse:.2f}')\n",
        "lr_monitor = LearningRateMonitor(logging_interval='step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P440xeJC9G6U"
      },
      "outputs": [],
      "source": [
        "# Initialize a trainer\n",
        "trainer = Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    max_epochs=30,\n",
        "    logger=[wandb_logger],\n",
        "    callbacks=[checkpoint_callback, lr_monitor],\n",
        "    log_every_n_steps=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc91ZNWE3h0_"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8mZYVGM3dOu"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Train the model âš¡\n",
        "torch.random.manual_seed(42)\n",
        "trainer.fit(s2_model, train_dataloaders=train_dataloader, \n",
        "            val_dataloaders=valid_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akJmK8Qo_gI-"
      },
      "source": [
        "### Show example predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S-Ff1GLIFlc"
      },
      "outputs": [],
      "source": [
        "model_name = wandb.run.name\n",
        "# model_name = 'playful-field-16'\n",
        "fn = os.listdir(os.path.join(model_checkpoint_path, model_name))[0]\n",
        "s2_model.load_state_dict(torch.load(os.path.join(model_checkpoint_path, model_name, fn))['state_dict'])\n",
        "s2_model.eval().cuda();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYog2Bkt8Fgi"
      },
      "outputs": [],
      "source": [
        "imgs, labels, _ = next(iter(valid_dataloader))\n",
        "pred = s2_model(imgs.cuda())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gZNQDZX7vMR"
      },
      "outputs": [],
      "source": [
        "s = 7\n",
        "fig, axes = plt.subplots(1, 3, figsize=(s*3, s))\n",
        "axes[0].imshow(ndimage.median_filter(labels[0].numpy()[0], 3))\n",
        "axes[1].imshow(pred[0].cpu().detach().numpy()[0])\n",
        "axes[2].imshow(ndimage.median_filter(labels[0].numpy()[0], 3) - pred[0].cpu().detach().numpy()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggQYrsAQ37cU"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WWTm_ELFoy8"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "output_dir = os.path.join(model_checkpoint_path, model_name, 'predicted')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "for chip_id in tqdm(pred_ids):\n",
        "    image = []\n",
        "    for month in range(12):\n",
        "        img = get_image_from_aws(rf\"test_features/{chip_id}_{MODE}_{month:02d}.tif\")\n",
        "        img = torch.tensor(img.astype(np.float32))\n",
        "        img = (img - torch.tensor(MEANS))/torch.tensor(STDS)\n",
        "        image.append(img)\n",
        "    image = torch.stack(image)\n",
        "\n",
        "    pred = s2_model(image.unsqueeze(0).cuda())\n",
        "    img = pred.squeeze().cpu().detach().numpy()\n",
        "    io.imsave(f\"{output_dir}/{chip_id}_agbm.tif\", img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwAhaaA2A7Gb"
      },
      "outputs": [],
      "source": [
        "fn = os.path.join(output_dir, '../submission')\n",
        "shutil.make_archive(fn, 'zip', output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbezI-A88kI2"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(fn + '.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prGCKPh4_4cU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAVVm66YLlElHnraB4Zi1X",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}